# Math-IA ğŸ¤–ğŸ“Š

Uma plataforma inteligente de IA que utiliza **Ollama** para gestÃ£o de modelos locais e **Milvus** como banco de dados vetorial, oferecendo capacidades avanÃ§adas de processamento de linguagem natural com contexto semÃ¢ntico.

## ğŸš€ CaracterÃ­sticas

- **GestÃ£o Multi-Modelo**: SeleÃ§Ã£o inteligente de modelos baseada no conteÃºdo da pergunta
- **Busca SemÃ¢ntica**: Utiliza embeddings para encontrar contexto relevante
- **RAG (Retrieval-Augmented Generation)**: Combina busca vetorial com geraÃ§Ã£o de texto
- **API REST**: Interface HTTP simples e eficiente
- **Arquitetura Modular**: CÃ³digo organizado em camadas bem definidas

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HTTP Client   â”‚â”€â”€â”€â–¶â”‚   API Routes    â”‚â”€â”€â”€â–¶â”‚   AI Handler    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Model Selector â”‚â—€â”€â”€â”€â”¤   Ollama Client â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Vector Search   â”‚â—€â”€â”€â”€â”¤ Milvus Database â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Estrutura do Projeto

```
math-ia/
â”œâ”€â”€ main.go                     # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ go.mod                      # DependÃªncias do projeto
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ ask.go              # Handlers da API REST
â”‚   â”œâ”€â”€ ia/
â”‚   â”‚   â”œâ”€â”€ ollama/             # Cliente Ollama
â”‚   â”‚   â”‚   â”œâ”€â”€ cliente.go      # Cliente HTTP base
â”‚   â”‚   â”‚   â”œâ”€â”€ generate.go     # GeraÃ§Ã£o de texto
â”‚   â”‚   â”‚   â””â”€â”€ embeding.go     # GeraÃ§Ã£o de embeddings
â”‚   â”‚   â”œâ”€â”€ selector/
â”‚   â”‚   â”‚   â””â”€â”€ selector.go     # SeleÃ§Ã£o inteligente de modelos
â”‚   â”‚   â””â”€â”€ vectorstore/
â”‚   â”‚       â”œâ”€â”€ milvus.go       # Cliente Milvus
â”‚   â”‚       â”œâ”€â”€ config/
â”‚   â”‚       â”‚   â””â”€â”€ milvus_config.go
â”‚   â”‚       â””â”€â”€ operations/
â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â””â”€â”€ routes.go           # ConfiguraÃ§Ã£o de rotas
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ ingest.go           # IngestÃ£o de documentos
â”œâ”€â”€ embedEtcd.yaml              # ConfiguraÃ§Ã£o etcd
â”œâ”€â”€ standalone_embed.sh         # Script de inicializaÃ§Ã£o
â””â”€â”€ user.yaml                   # ConfiguraÃ§Ã£o de usuÃ¡rio
```

## ğŸ› ï¸ Tecnologias

- **Go 1.24+**: Linguagem principal
- **Ollama**: Servidor de modelos de IA local
- **Milvus**: Banco de dados vetorial
- **Chi Router**: Framework HTTP minimalista
- **godotenv**: Gerenciamento de variÃ¡veis de ambiente

## ğŸ“‹ PrÃ©-requisitos

- Go 1.24 ou superior
- Ollama instalado e rodando
- Milvus rodando (local ou Docker)
- Modelos baixados no Ollama:
  - `llama3.1:8b`
  - `nomic-embed-text`
  - `codellama`
  - `hf.co/iamcoder18/AceMath-7B-Instruct-Q4_K_M-GGUF`

## âš™ï¸ ConfiguraÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <repository-url>
cd math-ia
```

2. Instale as dependÃªncias:
```bash
go mod tidy
```

3. Configure as variÃ¡veis de ambiente (`.env`):
```env
OLLAMA_HOST=http://localhost:11434
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

4. Execute a aplicaÃ§Ã£o:
```bash
go run main.go
```

## ğŸ”Œ Endpoints da API

### POST `/ask`
Faz uma pergunta simples sem contexto adicional.

**Request:**
```json
{
  "prompt": "Qual Ã© a derivada de xÂ²?"
}
```

**Response:**
```json
{
  "model": "hf.co/iamcoder18/AceMath-7B-Instruct-Q4_K_M-GGUF",
  "response": "A derivada de xÂ² Ã© 2x."
}
```

### POST `/ask-with-context`
Faz uma pergunta utilizando busca semÃ¢ntica para contexto adicional (RAG).

**Request:**
```json
{
  "prompt": "Como calcular uma integral definida?"
}
```

**Response:**
```json
{
  "model": "hf.co/iamcoder18/AceMath-7B-Instruct-Q4_K_M-GGUF",
  "response": "Para calcular uma integral definida..."
}
```

## ğŸ§  Modelos DisponÃ­veis

| Modelo | EspecializaÃ§Ã£o | Palavras-chave |
|--------|----------------|----------------|
| `AceMath-7B` | MatemÃ¡tica | integral, derivada, cÃ¡lculo, equaÃ§Ã£o |
| `codellama` | ProgramaÃ§Ã£o | python, golang, typescript, api |
| `llama3.1:8b` | Uso geral | Modelo padrÃ£o |
| `nomic-embed-text` | Embeddings | GeraÃ§Ã£o de vetores |

## ğŸ¯ SeleÃ§Ã£o Inteligente de Modelos

O sistema analisa o prompt e seleciona automaticamente o modelo mais adequado baseado em:

- **Palavras-chave especÃ­ficas** (com pesos diferentes)
- **Contexto semÃ¢ntico** da pergunta
- **EspecializaÃ§Ã£o** de cada modelo

Exemplo:
- "Como resolver esta integral?" â†’ `AceMath-7B-Instruct`
- "Escreva uma funÃ§Ã£o em Python" â†’ `codellama`
- "Explique sobre histÃ³ria" â†’ `llama3.1:8b`

## ğŸ“Š Fluxo RAG (Retrieval-Augmented Generation)

1. **Recebe pergunta** do usuÃ¡rio
2. **Gera embedding** da pergunta usando `nomic-embed-text`
3. **Busca similaridade** no Milvus (top-3 documentos)
4. **Seleciona modelo** baseado no conteÃºdo
5. **Gera resposta** usando contexto encontrado
6. **Retorna resposta** enriquecida

## ğŸš€ Deploy

### Docker Compose (recomendado)
```yaml
version: '3.8'
services:
  math-ia:
    build: .
    ports:
      - "8081:8081"
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - MILVUS_HOST=milvus
      - MILVUS_PORT=19530
    depends_on:
      - ollama
      - milvus
```

### Standalone
```bash
# Build
go build -o math-ia main.go

# Run
./math-ia
```

## ğŸ”§ Desenvolvimento

### Estrutura de Dados
```go
type Document struct {
    ID      int64  `json:"id"`
    Text    string `json:"text"`
    Source  string `json:"source"`
    Content string `json:"content"`
}
```

### Adicionando Novos Modelos
1. Baixe o modelo no Ollama
2. Adicione em `selector.go`:
```go
WeightedKeywordsByModel["novo-modelo"] = map[string]int{
    "palavra-chave": 3,
}
```

## ğŸ“ˆ Monitoramento

A aplicaÃ§Ã£o inclui:
- **Logs estruturados** para debugging
- **CORS configurado** para frontend
- **Tratamento de erros** robusto
- **Timeouts configurÃ¡veis**

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ†˜ Suporte

- **DocumentaÃ§Ã£o**: Este README
---

Feito com â¤ï¸ usando Go e tecnologias de IA modernas.
